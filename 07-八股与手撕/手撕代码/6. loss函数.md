```python
import numpy as np

# 均方误差 (MSE) - 通常数值稳定，无需特殊处理
def mean_squared_error(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

# 类别交叉熵 (Categorical Cross-Entropy) - 添加平滑项
def categorical_cross_entropy(y_true, y_pred, epsilon=1e-15):
    # 防止 log(0)，添加小 epsilon
    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
    return -np.sum(y_true * np.log(y_pred))

# 二元交叉熵 (Binary Cross-Entropy) - 添加平滑项
def binary_cross_entropy(y_true, y_pred, epsilon=1e-15):
    # 防止 log(0)，添加小 epsilon
    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

# 示例用法
if __name__ == "__main__":
    # 假设数据
    y_true = np.array([1, 0, 1, 1])
    y_pred = np.array([0.9, 0.1, 0.8, 0.7])
    
    # 计算损失
    mse = mean_squared_error(y_true, y_pred)
    cce = categorical_cross_entropy(y_true, y_pred)
    bce = binary_cross_entropy(y_true, y_pred)
    
    print(f"MSE: {mse}")
    print(f"Categorical Cross-Entropy: {cce}")
    print(f"Binary Cross-Entropy: {bce}")
```

