# Prompt Tuning

## PEFT：参数高效微调

PEFT（Parameter-Efficient Fine-Tuning，参数高效微调）是一种通过仅调整预训练模型的少量参数或引入额外可训练模块来实现高效任务适配的技术。其核心目标是在保持模型性能的同时，显著降低计算资源消耗、存储成本和训练时间

PEFT 的核心逻辑是冻结预训练模型的大部分参数，仅针对特定任务调整少量关键参数或新增轻量级模块。常见技术包括：

1. **适配器（Adapter）**：在模型层间插入小型神经网络模块（如全连接层），仅训练适配器参数。例如，在 Transformer 的 FFN 层前后添加适配器，冻结原始权重。
2. **LoRA（Low-Rank Adaptation）**：通过低秩矩阵分解近似权重矩阵的更新，将原始高秩矩阵分解为两个低秩矩阵的乘积（如*W*=*W*0+*B**A*），仅训练*B*和*A*，从而减少可训练参数数量。LoRA 的扩展版本 QLoRA 进一步结合 4 位量化技术，将显存占用降低 75% 以上。
3. **Prefix Tuning/Prompt Tuning**：在模型输入层添加可训练的前缀嵌入或软提示（soft prompt），通过引导模型输出适应任务。例如，P-Tuning v2 通过深层注入提示提升效果。
4. **混合专家（MoE）结合 PEFT**：如 MoV、MoLORA 等方法，在 MoE 框架中为每个专家添加 LoRA 模块，通过路由机制动态激活相关专家，进一步提升参数效率。实验表明，MoV 仅用 0.32% 可训练参数即可达到接近全量微调的性能。