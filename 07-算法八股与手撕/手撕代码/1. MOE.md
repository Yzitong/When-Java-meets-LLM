```python
import torch
from torch import nn

# ---------------------- 1. 专家网络（单个Expert） ----------------------
class ExpertNetwork(nn.Module):
    def __init__(self, hidden_size, intermediate_size):
        super().__init__()
        self.hidden_size = hidden_size
        self.intermediate_size = intermediate_size
        # 两层线性网络 + ReLU，模拟FFN结构
        self.linear1 = nn.Linear(hidden_size, intermediate_size)
        self.linear2 = nn.Linear(intermediate_size, hidden_size)

    def forward(self, x):
        x = self.linear1(x)       # 降维/升维（依参数设计）
        x = nn.functional.relu(x) # 激活函数
        return self.linear2(x)    # 恢复维度


# ---------------------- 2. 路由层（Router）：选Top-K专家 ----------------------
class Router(nn.Module):
    def __init__(self, hidden_size, expert_num, top_k):
        super().__init__()
        self.router = nn.Linear(hidden_size, expert_num)  # 预测每个专家的权重
        self.top_k = top_k                                # 动态激活的专家数（如Top-2）

    def forward(self, x):
        # 1. 展平输入：(batch*seq, hidden_size)
        x = x.view(-1, x.size(-1))  
        # 2. 计算专家权重 + Softmax归一化
        expert_weights = self.router(x)
        expert_weights = nn.functional.softmax(expert_weights, dim=-1)
        # 3. 选Top-K专家的权重和索引（非排序，提升效率）
        topk_weight, topk_idx = torch.topk(
            expert_weights, 
            k=self.top_k, 
            dim=-1, 
            sorted=False
        )
        # 4. 权重重新归一化（保证Top-K权重和为1）
        topk_weight = topk_weight / topk_weight.sum(dim=-1, keepdim=True)
        return topk_weight, topk_idx


# ---------------------- 3. MoE层（整合专家+路由） ----------------------
class MOELayer(nn.Module):
    def __init__(self, hidden_size, intermediate_size, expert_num, top_k):
        super().__init__()
        self.hidden_size = hidden_size
        self.intermediate_size = intermediate_size
        self.expert_num = expert_num  # 专家总数（如8个）
        self.top_k = top_k            # 每个token激活的专家数（如2个）
        
        # 初始化专家集合（多个ExpertNetwork）
        self.experts = nn.ModuleList([
            ExpertNetwork(hidden_size, intermediate_size) 
            for _ in range(expert_num)
        ])
        # 初始化路由模块
        self.router = Router(hidden_size, expert_num, top_k)

    def forward(self, x):
        # 输入形状：(batch_size, seq_len, hidden_size)
        batch_size, seq_len, _ = x.size()
        token_num = batch_size * seq_len  # 总token数：batch×seq_len
        x_flat = x.view(token_num, self.hidden_size)  # 展平为二维
        
        # Step 1：路由选择Top-K专家
        topk_weight, topk_idx = self.router(x_flat)  
        
        # Step 2：初始化输出张量（与输入同形）
        output = torch.zeros_like(x_flat)
        
        # Step 3：逐个token调用专家，加权求和
        for token_idx in range(token_num):
            for k in range(self.top_k):
                # 获取当前token第k个专家的索引和权重
                expert_idx = topk_idx[token_idx, k]
                weight = topk_weight[token_idx, k]
                # 调用专家网络，累加加权结果
                output[token_idx] += weight * self.experts[expert_idx](x_flat[token_idx])
        
        # 恢复原始形状：(batch_size, seq_len, hidden_size)
        return output.view(batch_size, seq_len, self.hidden_size)


# ---------------------- 4. 测试代码 ----------------------
if __name__ == "__main__":
    # 超参数（模拟大模型配置）
    HIDDEN_SIZE = 4096       # 隐藏层维度（如DeepSeek的4096）
    INTERMEDIATE_SIZE = 2048 # 专家中间层维度（通常是隐藏层的2~4倍）
    EXPERT_NUM = 8           # 专家总数（如8个）
    TOP_K = 2                # 每个token激活2个专家
    
    # 构造输入：(batch=2, seq_len=11, hidden_size=4096)
    inputs = torch.randn((2, 11, 4096))
    
    # 实例化MoE层
    moe_layer = MOELayer(
        hidden_size=HIDDEN_SIZE, 
        intermediate_size=INTERMEDIATE_SIZE, 
        expert_num=EXPERT_NUM, 
        top_k=TOP_K
    )
    
    # 前向传播
    outputs = moe_layer(inputs)
    print("输出形状:", outputs.size())  # 应输出: torch.Size([2, 11, 4096])
```

