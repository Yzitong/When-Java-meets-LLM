## LoRA微调的基本原理

LoRA 通过 **“低秩矩阵近似参数更新 + 冻结主权重”**，实现了 **参数量少、训练快、推理无开销** 的高效微调，尤其适合大模型的领域适配和多任务定制。实验证明：**多矩阵+小秩** 的组合，能在低计算成本下达到优异性能，是当前大模型微调的主流方案。

论文地址：https://arxiv.org/abs/2106.09685

B站论文精读：[【AI论文精读】爆火的stable-diffusion微调方法lora论文逐段精读(上)_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV13h411G7aY/?spm_id_from=333.337.search-card.all.click&vd_source=aa6afb9d0536d09ecdcb5d2c1fcf4c79)

<img src="https://raw.githubusercontent.com/Yzitong/LLM-Mastery-Journey/main/images/image-20250707184435678.png" alt="image-20250707184435678" style="zoom:67%;" />

## 一、核心思想：低秩近似的参数高效微调

LoRA 基于 **“大模型微调时，参数更新量（ΔW）具有低秩性”** 的假设：

- 预训练模型的主权重（( W_0 )）冻结，不再更新；
- 通过 **两个低秩矩阵（A、B）** 近似参数变化（ΔW = B·A），仅训练这两个矩阵，大幅减少可训练参数量。
- 通过在模型的关键层（多头注意力和Feed-Forward）中添加低秩矩阵，并将其加到原始权重矩阵上。该方法不用改变整个模型的结构，在推理时不需要额外的计算量，并且能保持原有的性能。
- 与之相比，Adapter引入了额外的层，该层必须按顺序处理，影响并行训练；Prefix-tuning在用户输入前加可训练的前缀，减少了可用于处理下游任务的sequence长度，性能较差。

## 二、模型结构：旁支低秩矩阵的设计

对 Transformer 等模型的 **关键层（如多头注意力、FFN 层）**，引入低秩矩阵：

1. 矩阵定义：

   - ( A$ \in \mathbb{R}^{d \times r}$ )：将输入维度从 ( d ) 降为 ( r )（($ r \ll d $)，即“秩”，控制复杂度）；
   - ( B $\in \mathbb{R}^{r \times d}$ )：将维度从 ( r ) 升回 ( d )。

2. 前向计算：

   ![image-20250707191140525](https://raw.githubusercontent.com/Yzitong/LLM-Mastery-Journey/main/images/image-20250707191140525.png)

   - 原始参数W0，在旁边新建一个网络，只微调A，B矩阵，其维度远低于W0的维度。
   - 初始时，( A ) 高斯初始化，B初始化为全0矩阵（第一轮训练时，权重矩阵和不加A，B时一样，保证训练起始时模型行为与预训练一致，减少波动）。
   - 当切换一个下游任务时，只需减去原来的AB，替换为A'B'
   - loRA矩阵可以很容易的与其他的训练方法一起叠加作用。
   - loRA可以看做是全量微调的一个泛化的形式，随着A，B的秩r的增大，增大到d（512特征维度）时，LoRA就收敛到了原始模型
   - ΔW和W之间的关系 :ΔW 放大了W中未强调的方向，且放大系数相当大。并且 ΔW 放大了下游任务的重要特征，这些特征尽管W学习到了，但并未强调。

## 三、训练与推理的特点

| 阶段         | 核心行为                                                     | 优势                                   |
| ------------ | ------------------------------------------------------------ | -------------------------------------- |
| **训练**     | 仅更新 ( A ) 和 ( B )，参数量从 ($ d^2$ ) 降至 ( 2rd )（如 ( d=1024, r=8 )，参数量减百倍），论文中说实际微调的参数只占原来参数的1% | 算力、显存成本低，普通显卡可微调大模型 |
| **推理**     | 将 ( B·A ) 合并到 ( W_0 ) 中（( $W_{\text{新}} = W_0 + B·A $)），与原模型结构完全兼容 | 无额外计算开销，推理速度不变           |
| **任务切换** | 只需替换 ( A ) 和 ( B )，灵活适配多任务                      | 多任务微调成本极低                     |

## 四、关键参数的作用

### 1. **秩 ( r )**：

- **物理意义**：决定低秩矩阵的“表达能力”（( r ) 越小，参数越精炼，梯度方向更明确，收敛更快；( r ) 越大，拟合能力越强，但参数量增加）。
- 实验结论：
  - 若下游任务与预训练 **差异小**，小 ( r )（如 ($ r=1 \sim 8$ )）即可保证高准确率；
  - 若任务 **差异大**，需适当增大 ( r )（如 ( $r=16 \sim 64$ )）。

![image-20250707192225261](https://raw.githubusercontent.com/Yzitong/LLM-Mastery-Journey/main/images/image-20250707192225261.png)

### 2. **超参数 ( \alpha )**：

- **公式扩展**：![image-20250707192240269](https://raw.githubusercontent.com/Yzitong/LLM-Mastery-Journey/main/images/image-20250707192240269.png)
- **作用**：控制低秩矩阵对主权重的影响，间接调节训练步长（类似学习率，实验初期固定，后续不调整）。

## 五、应用策略：矩阵选择与 ( r ) 优化

1. **矩阵选择**：
   优先在 **多个参数矩阵**（如注意力的 ( W_q, W_k, W_v, W_o ) 及 FFN 层）上应用 LoRA，**即使每个矩阵的 ( r ) 很小，也比单个矩阵用大 ( r ) 效果更好**（实验验证：多矩阵+小 ( r ) 准确率更高，如 WikiSQL、MultiNLI 任务）。
2. **( r ) 取值建议**：
   - 任务与预训练 **接近**：选小 ( r )（如 ($ r=1 \sim 8 $)），兼顾效率与效果；
   - 任务 **差异大**：适当增大 ( r )（如 ( $r=16 \sim 64$ )），增强拟合能力。

![image-20250707192524646](https://raw.githubusercontent.com/Yzitong/LLM-Mastery-Journey/main/images/image-20250707192524646.png)

## 六、对比优势：为何 LoRA 更高效？

| 方法              | 缺陷                                   | LoRA 优势                        |
| ----------------- | -------------------------------------- | -------------------------------- |
| **Adapter**       | 引入额外层，需顺序计算，**破坏并行性** | 不改模型结构，训练/推理都高效    |
| **Prefix-tuning** | 前缀占用序列长度，下游任务可用长度减少 | 不占用输入长度，保留模型完整能力 |